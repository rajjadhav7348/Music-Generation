
# ğŸµ Music Generation with AI  
Author: **rajjadhav7348**

---

## ğŸš€ Project Overview

This project explores the use of deep learning, particularly LSTM (Long Short-Term Memory) networks, to generate music.  
The model is trained on MIDI files and learns patterns in note sequences to generate new, original music.

The project supports:
- Automatic MIDI parsing
- Sequence preparation for training
- Model building using LSTM
- Music generation from trained weights
- Saving generated sequences as MIDI

---

## ğŸ§  Key Features

- âœ… LSTM-based sequence model for music learning  
- âœ… Handles chords and individual notes  
- âœ… Converts generated notes into MIDI format  
- âœ… Automatically creates a test MIDI file if none exist  
- âœ… Training checkpoints saved for reuse or generation

---

## ğŸ“ Directory Structure

```
music-generation/
â”œâ”€â”€ midi_songs/             # Folder containing .mid files
â”‚   â””â”€â”€ sample.mid          # Example created if no files exist
â”œâ”€â”€ weights/                # Trained model weights (optional)
â”œâ”€â”€ train.py                # Script to parse, train, and generate
â”œâ”€â”€ generate.py             # Optional: script to generate music
â””â”€â”€ README.md               # This file
```

---

## âš™ï¸ Requirements

Install required libraries using:

```bash
pip install tensorflow music21 numpy
```

Python version: **3.7+**

---

## ğŸ› ï¸ How It Works

1. **MIDI Collection**: All `.mid` files in `midi_songs/` are parsed using `music21`.
2. **Note Extraction**: Notes and chords are extracted into sequences.
3. **Sequence Preparation**: Sequences are converted to integer encoding and split into input/output.
4. **Model Training**: A stacked LSTM model is trained to predict next notes.
5. **Music Generation**: The model generates new music notes, saved as a new `.mid` file.

---

## â–¶ï¸ How to Run

### Step 1: Add MIDI Files

Put MIDI files into the folder `midi_songs/`. If empty, a sample file is auto-created.

### Step 2: Train the Model

```bash
python train.py
```

Optional (if generation code is separate):

```bash
python generate.py
```

---

## ğŸ Output

* Training prints loss and saves best weights (e.g., `weights-improvement-05-1.2345.hdf5`)
* Generated MIDI file is saved as `output.mid` or similar
* Can be opened in any MIDI player (MuseScore, LMMS, etc.)

---

## ğŸ§© Sample Notes Generated

```
['C4', 'D4', 'E4', 'F4', 'G4', 'A4', 'B4', 'C5']
```

---

## ğŸ’¡ Tips

* Increase the dataset size for better generation quality
* Reduce sequence length for faster training
* Train longer (more epochs) to generate more complex music
* Use genres (classical, jazz) as focused datasets

---

## ğŸ“¬ Contact

**Author:** rajjadhav7348  
You can reach me through GitHub or community forums for questions and collaboration.

---
